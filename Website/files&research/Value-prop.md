- Le problÃ¨me avec Vibe coding
    
    Voici une version enrichie et sourcÃ©e de la section **ğŸš« La rÃ©alitÃ© "Vibe coder"**, avec des donnÃ©es concrÃ¨tes pour appuyer chaque point :
    
    ---
    
    ## ğŸš« La rÃ©alitÃ© "Vibe coder"
    
    La croyance selon laquelle les LLMs pourraient coder de maniÃ¨re totalement autonome est largement rÃ©pandueâ€¦ mais elle est **trompeuse et dangereuse**.
    
    ### ğŸ“‰ Taux de rÃ©ussite rÃ©el
    
    - Des Ã©tudes montrent que mÃªme les meilleurs LLMs atteignent environ 70â€“88â€¯% de succÃ¨s sur des tÃ¢ches de codage benchmark, mais cela concerne des problÃ¨mes relativement simples et bien dÃ©finis. Sur des tÃ¢ches plus complexes (ou en usage rÃ©el), le taux chute bien en-dessous. Par exemple, StarCoder obtient moins de 35â€¯% de pass@1 sur les benchmarks HumanEval/MBPP, contre 73â€¯% pour ChatGPT (GPTâ€‘3.5) et 88â€¯% pour GPTâ€‘4â€¯([maksimkrupenin.medium.com](https://maksimkrupenin.medium.com/genai-experiment-can-llms-generate-a-fully-functional-production-ready-application-ab645ed1e5ee?utm_source=chatgpt.com), [mapsworkshop.github.io](https://mapsworkshop.github.io/assets/LLM_Code_Error_Analysis_MAPS2023_camera-ready.pdf?utm_source=chatgpt.com)).
    - En situations "one-shot" sans suivi ou vÃ©rification, le code utilisable dÃ¨s la premiÃ¨re production est souvent sous les 20â€¯% en productionâ€¯.
    
    ### ğŸ Erreurs courantes
    
    1. **Prompts flous ou hors contexte**
        - Sans contexte clair, les LLM Ã©crivent un code "gÃ©nÃ©rique" qui ne correspond pas Ã  lâ€™architecture de votre projetâ€¯([medium.com](https://medium.com/%40adnanmasood/code-generation-with-llms-practical-challenges-gotchas-and-nuances-7b51d394f588?utm_source=chatgpt.com)).
    2. **Objectifs non dÃ©finis ou incomplets**
        - Les LLM gÃ©nÃ¨rent le code sur ce quâ€™ils "croient" devoir faire, souvent sans inclure les parties essentielles (cas dâ€™usage, contrÃ´les, testsâ€¦)â€¯.
    3. **Absence de vÃ©rification ou tests automatisÃ©s**
        - Jusquâ€™Ã  40â€¯% des snippets gÃ©nÃ©rÃ©s par GitHub Copilot contiennent des vulnÃ©rabilitÃ©s exploitablesâ€¯([medium.com](https://medium.com/%40adnanmasood/code-generation-with-llms-practical-challenges-gotchas-and-nuances-7b51d394f588?utm_source=chatgpt.com)).
        - Une Ã©tude rÃ©cente identifie des bugs typiques (pannes logiques, erreurs de syntaxe, cas limites non traitÃ©sâ€¦) dans quasiment tous les extraits de code testÃ©sâ€¯.
    
    ### âš ï¸ Ce que cela signifie
    
    - Le code peut **compiler sans erreur**, mais **Ã©chouer silencieusement** ou provoquer des failles de sÃ©curitÃ©â€¯.
    - Les LLM **hallucinent du code**, inventent des fonctions ou usages inexistantsâ€¯([simonwillison.net](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/?utm_source=chatgpt.com)).
    - La qualitÃ© varie Ã©normÃ©ment selon le prompt, le contexte et la rigueur de lâ€™architecte humain pour guider lâ€™agentâ€¯([confident-ai.com](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation?utm_source=chatgpt.com)).
    
    ---
    
    ### âœ… Notre approche : remplacer le "vibe" par lâ€™"agentic"
    
    - Nous montrons **comment structurer les prompts**, dÃ©finir des **spÃ©cifications claires**, et mettre en place des **tests oracles** dÃ¨s la premiÃ¨re gÃ©nÃ©ration.
    - Nous introduisons lâ€™**orchestration dâ€™agents**, la **vÃ©rification continue**, la **mÃ©moire de contexte**, et les **boucles de feedback** (test â†’ debug automatique).
    - Bref : on ne se contente pas de "vibe", on **construit un systÃ¨me fiable, mesurable et Ã©volutif**.
    
    Souhaites-tu que jâ€™intÃ¨gre ces points dans une proposition visuelle (schÃ©ma, slide) pour illustrer cette fractureâ€‰?
    

# **ProblÃ¨me Ã  rÃ©soudre**

Les petites Ã©quipes techniques, les freelances et les agences sont aujourdâ€™hui confrontÃ©s Ã  un paradoxe :

> les outils dâ€™IA promettent des gains de productivitÃ© majeurs, mais leur adoption est lente, fragmentÃ©e, et souvent dÃ©cevante.
> 

### 1. Vibe coding nâ€™arrive pas Ã  satisfaire les attentes

- Les utilisateurs attendent des agents une autonomie complÃ¨te sur des tÃ¢ches complexes.
- En rÃ©alitÃ©, le taux de succÃ¨s des prompts one-shot est trÃ¨s faible (<20%) pour du code exÃ©cutable en production.
- La cause : absence de structure, de vÃ©rification, de contexte.

### 2. Manque de connaissance sur comment dÃ©finir le contexte des agents

- Les dÃ©veloppeurs nâ€™ont pas de mÃ©thode claire pour :
    - DÃ©finir les objectifs du projet
    - SpÃ©cifier les outputs attendus
    - Encadrer les agents avec des contraintes explicites (temps, format, validations)

### 3. Brouillard technologique

- Trop d'outils, trop vite : chaque mois une nouvelle plateforme ou technique IA.
- DifficultÃ© Ã  suivre les Ã©volutions sans documentation claire.
- Frustration liÃ©e Ã  des rÃ©sultats inconstants, mal compris, difficilement rÃ©plicables.

### 4. Adoption chaotique de lâ€™IA

- TestÃ©s : ChatGPT, Copilot, Claude...
- Mais toujours sans cadre, sans structure de prompt, sans vÃ©rification.
- RÃ©sultat : perte de temps, instabilitÃ©, mÃ©fiance envers lâ€™IA.

### 5. Risque de se faire dÃ©passer

- Les workflows stagnent pendant que les outils sâ€™amÃ©liorent.
- Ceux qui n'adaptent pas leur faÃ§on de travailler deviennent moins compÃ©titifs.
- Les Ã©quipes qui ne forment pas de "context-aware agents" seront dÃ©passÃ©es par celles qui savent orchestrer et automatiser intelligemment.

---

## **Segment cible**

Notre offre sâ€™adresse aux dÃ©veloppeurs qui ont **dÃ©jÃ  commencÃ© Ã  utiliser des outils dâ€™IA** mais qui nâ€™ont pas encore rÃ©ussi Ã  les transformer en vÃ©ritable levier de croissance :

| Segment | Besoin principal |
| --- | --- |
| ğŸ‘¨â€ğŸ’¼ Freelance / Solo dev | Gagner du temps, livrer plus vite sans sacrifier la qualitÃ©. |
| ğŸ¤  CTO de startup (1â€“5 devs) | AccÃ©lÃ©rer l'onboarding, scaler efficacement sans recruter davantage. |
| ğŸ§  Agence technique | Standardiser les livrables, optimiser la marge et amÃ©liorer la qualitÃ© globale. |
| ğŸ« Groupe dâ€™Ã©tudiants/Ã©coles | MaÃ®triser les outils AI essentiels avant d'entrer sur le marchÃ© du travail. |
| ğŸ“š Ã‰quipe de dÃ©veloppeurs | Onboarding rapide, comprÃ©hension de codebase client, sprints plus prÃ©dictibles, sÃ©curitÃ© accrue. |

---

## ğŸ’¡ **Proposition de valeur**

**contextDev transforme votre stack de dÃ©veloppement en machine de livraison AI-native. Nous ne dÃ©veloppons pas le moteur, nous vous apprenons Ã  comment conduire la voiture.**

> Nous installons, configurons et vous coachons sur les workflows IA les plus efficaces pour livrer plus vite, avec moins de fatigue, et sans embaucher plus.
> 

---

## ğŸ› ï¸ Notre solution : transmettre les bons rÃ©flexes IA

Notre approche repose sur **la formation appliquÃ©e**, enrichie dâ€™un accompagnement ponctuel et personnalisÃ©. Nous ne dÃ©ployons pas vos agents pour vous : nous vous enseignons Ã  le faire vous-mÃªme, avec rigueur, autonomie et mÃ©thode.

### ğŸ¯ Ce que nous faisons :

- **Analyse ciblÃ©e de vos opÃ©rations** : on sâ€™assoit avec vous pour comprendre vos enjeux, vos outils et vos projets.
- **Ã‰valuation du potentiel IA** : on identifie les points d'entrÃ©e les plus prometteurs pour l'automatisation ou l'orchestration.
- **Formation actionnable** : vous recevez nos frameworks, nos modÃ¨les de prompts, nos checklists de design, et nos meilleurs exemples de mise en place rÃ©ussie.
- **Mise en situation guidÃ©e** : exemples concrets appliquÃ©s Ã  vos cas rÃ©els, sans jamais toucher Ã  votre infra.
- **Support asynchrone** : possibilitÃ© de nous recontacter plus tard pour dÃ©bloquer des points spÃ©cifiques ou ajuster les pratiques.

### ğŸ§© Ce que nous ne faisons pas :

- ImplÃ©menter Ã  votre place
- DÃ©pendre dâ€™une relation longue durÃ©e
- Prendre le contrÃ´le de vos outils ou Ã©quipes

> Nous ne construisons pas vos agents, nous vous donnons le manuel, la mÃ©thode et les bons rÃ©flexes pour quâ€™ils vous obÃ©issent vraiment.
> 

---

## ğŸš€ **Notre diffÃ©renciation**

| contextDev | Alternatives actuelles |
| --- | --- |
| âœ… ImplÃ©mentation sur-mesure, main dans la main | âŒ Plateformes de formation gÃ©nÃ©riques |
| âœ… RÃ©sultats mesurables en 14â€“30 jours | âŒ Freelances ponctuels, pas de mÃ©thode globale |
| âœ… SpÃ©cialisÃ© dev + agents AI + productivitÃ© | âŒ Consulting dâ€™entreprise (trop cher / trop lent) |
| âœ… Outils continuellement mis Ã  jours | âŒ Outils figÃ©s ou non adaptÃ©s aux petites Ã©quipes |

## âš–ï¸ **Pourquoi câ€™est le bon moment**

- Lâ€™adoption dâ€™outils IA explose, **mais les bÃ©nÃ©fices restent limitÃ©s** car les devs sont livrÃ©s Ã  eux-mÃªmes.
- Les leaders techniques savent que sâ€™ils nâ€™automatisent pas **maintenant**, ils prendront du retard.
- Les meilleures Ã©quipes de demain seront **â€œcontext-awareâ€** : rapides, coordonnÃ©es, outillÃ©es, augmentÃ©es.

---

## âš›ï¸ Ã‰volution des outils IA

L'Ã©cosystÃ¨me des outils IA a Ã©voluÃ© rapidement, passant d'outils gÃ©nÃ©ralistes Ã  des systÃ¨mes orchestrables et spÃ©cialisÃ©s. Comprendre cette Ã©volution permet de situer la valeur de notre formation.

| Outil | Fonction principale | Points forts | Limites / Blind spots |
| --- | --- | --- | --- |
| ChatGPT | Assistant gÃ©nÃ©raliste | Souple, conversationnel | Pas dâ€™accÃ¨s au codebase, pas de contexte persistant |
| Cursor | Ã‰diteur IA contextuel | IDE + IA, context awareness | Pas dâ€™orchestration, pas d'agents multiples |
| RooCode | IDE orchestrateur avec agents | Multi-modes, MCP, Ã©volution constante | ComplexitÃ© de configuration initiale |
| Claude-code | ExÃ©cuteur prÃ©cis, orientÃ© code | Structure logique, qualitÃ© de sortie | Plus cher, nÃ©cessite prompts experts |
| Claude-code + Orchestration dâ€™agents | SystÃ¨me autonome et auto-amÃ©liorant | FiabilitÃ©, coordination, productivitÃ© scalable | Requiert structuration claire du contexte, orchestration maÃ®trisÃ©e |

Cette Ã©volution peut Ãªtre illustrÃ©e par un **arbre de complexification** des outils, allant de lâ€™assistant simple au systÃ¨me coordonnÃ© avec agents, context memory et tests oracles.

---

## ğŸš« La rÃ©alitÃ© "Vibe coder"

Il existe une croyance largement rÃ©pandue que les LLM peuvent coder seuls de maniÃ¨re autonome. Câ€™est une **fausse conception**.

- **Taux de succÃ¨s rÃ©el** : <20% des prompts one-shot donnent un rÃ©sultat utilisable en production sans retouche.
- **Erreurs courantes** :
    - Prompt flou, non contextualisÃ©
    - Objectifs non dÃ©finis
    - Aucune vÃ©rification ou test des outputs

### ğŸ‹ï¸ Comparatif Vibe coder / Agentic coder

|  | Vibe Coder | Agentic Coder |
| --- | --- | --- |
| Usage | Prompt one-shot | Orchestration planifiÃ©e |
| Autonomie | Faible, pilotÃ© Ã  la main | ElevÃ©e, agents guidÃ©s par des MCP |
| RÃ©sultats | ImprÃ©visibles, variables | PrÃ©dictibles et mesurables |
| Ã‰volutivitÃ© | Individuelle, Ã©phÃ©mÃ¨re | SystÃ©mique, cumulable |

---

## ğŸ‘¨â€ğŸ’» Le "Agentic Coder"

Le cÅ“ur de notre approche repose sur la **conception de prompts systÃ©miques** et une **orchestration logique des agents**.

### Nos piliers :

- **Test Oracle** : lâ€™agent peut-il vÃ©rifier lui-mÃªme la validitÃ© de sa sortie ?
- **SpÃ©cification claire** : objectifs, contraintes, mÃ©triques
- **Autonomie guidÃ©e via MCP** : assigner des rÃ´les Ã  chaque agent
- **Directive design** : prompts structurÃ©s et imbriquÃ©s

### ğŸ§ Quels ModÃ¨les LLM choisir?

| RÃ´le | ModÃ¨le | Avantages | Usage idÃ©al |
| --- | --- | --- | --- |
| Planneur | Gemini 2.5 | Reasoning avancÃ©, large context | Planification, spÃ©cification |
| ExÃ©cuteur | Claude-code | Code propre, rapide, langages variÃ©s | ImplÃ©mentation, unit tests |
| Autres | Mix LLM | Mix Claude, GPT, Mixtral selon besoin | Orchestration adaptÃ©e aux cas dâ€™usage |

### â“ Comment choisir ?

- **Budget**
- **CapacitÃ© de raisonnement?**
- **FenÃªtre de contexte?**
- **DÃ©terministique ou crÃ©atif?** : projet exploratoire = tempÃ©rature haute; projet critique = tempÃ©rature basse, modÃ¨le cohÃ©rent

---

## ğŸ“„ Ce que nous proposons

> Nous ne construisons pas le moteur, nous vous apprenons Ã  piloter la voiture.
> 
- Construire un **contexte exÃ©cutable** pour les agents (MCP)
- Ã‰crire des **spÃ©cifications produit viables** pour LLMs
- Techniques dâ€™**onboarding rapide sur un codebase** avec agents
- **Configuration dâ€™environnement** : IDE, RooCode, MCP, paramÃ¨tres optimisÃ©s
- Projets pratiques avec **design + prompt design + test oracles**
- Comprendre **comment les agents coordonnent, mÃ©morisent, communiquent**
- Sâ€™assurer que la gÃ©nÃ©ration de code peut atteindre une qualitÃ© de production.
- Vous informer sur les â€œguardrailsâ€ nÃ©cessaires pour surveiller vos agents.
- **Aspects sÃ©curitÃ©** : isolation, audit, logs, gouvernance

---

## ğŸ”§ Stack et outils couverts

- **Orchestration dâ€™agents :** Apprendre Ã  concevoir des workflows multi-agents pour dÃ©boguer, coder et tester de maniÃ¨re collaborative, automatisÃ©e et itÃ©rative.
- **Exemples de spÃ©cifications produit (PRD) :** Construire des documents comprÃ©hensibles par des agents, pour garantir un alignement clair et exploitable.
- **DÃ©finition du contexte projet :** Formuler le cadre et les objectifs afin de rÃ©duire drastiquement le taux dâ€™Ã©chec et aligner les agents sur les rÃ©sultats attendus.
- **SpÃ©cifications techniques (SDD) :** Documenter les choix de design, d'architecture et les contraintes techniques dans un format structurÃ©.
- **Agent Orchestration avancÃ©e :** Comprendre en profondeur la coordination des agents, leur gestion de mÃ©moire et leur logique interne. Ne pas traiter lâ€™IA comme une boÃ®te noire.
- **MCP personnalisÃ© :** CrÃ©ation et mise Ã  jour dâ€™un MCP selon les rÃ´les, le contexte et les contraintes propres Ã  votre projet.
- **Prise en main des outils :**
    - Cursor : Ã©diteur IA augmentÃ© avec des limites dâ€™orchestration
    - Claude-code : moteur dâ€™exÃ©cution fiable et structurÃ©
    - RooCode : gestion multi-modes (chercheur, codeur, dÃ©veloppeur, orchestrateur)
- **Et bien plus :** formation Ã  la sÃ©curitÃ©, architecture de projet, bonnes pratiques de gouvernance et dÃ©ploiement.